{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTMs for Time Series Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now build a slightly deeper model by stacking two LSTM layers using the Quandl stock price data. Furthermore, we will include features that are not sequential in nature, namely indicator variables for identifying the equity and the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:42.482106Z",
     "start_time": "2021-02-23T15:28:42.479679Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:45.750453Z",
     "start_time": "2021-02-23T15:28:42.646677Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:43:33.602033: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, concatenate, Embedding, Reshape, BatchNormalization\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:45.829343Z",
     "start_time": "2021-02-23T15:28:45.752524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:43:35.032750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:35.049334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:35.049419: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:45.838328Z",
     "start_time": "2021-02-23T15:28:45.831137Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:46.890619Z",
     "start_time": "2021-02-23T15:28:46.887596Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'lstm_embeddings')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data produced by the notebook [build_dataset](00_build_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:55.202828Z",
     "start_time": "2021-02-23T15:28:53.833048Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'returns_weekly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:55.296142Z",
     "start_time": "2021-02-23T15:28:55.207089Z"
    }
   },
   "outputs": [],
   "source": [
    "data['ticker'] = pd.factorize(data.index.get_level_values('ticker'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:55.897764Z",
     "start_time": "2021-02-23T15:28:55.301600Z"
    }
   },
   "outputs": [],
   "source": [
    "data['month'] = data.index.get_level_values('date').month\n",
    "data = pd.get_dummies(data, columns=['month'], prefix='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:56.149790Z",
     "start_time": "2021-02-23T15:28:55.904970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1167341 entries, ('A', Timestamp('2009-01-11 00:00:00')) to ('ZUMZ', Timestamp('2017-12-31 00:00:00'))\n",
      "Data columns (total 67 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   fwd_returns  1167341 non-null  float64\n",
      " 1   1            1167341 non-null  float64\n",
      " 2   2            1167341 non-null  float64\n",
      " 3   3            1167341 non-null  float64\n",
      " 4   4            1167341 non-null  float64\n",
      " 5   5            1167341 non-null  float64\n",
      " 6   6            1167341 non-null  float64\n",
      " 7   7            1167341 non-null  float64\n",
      " 8   8            1167341 non-null  float64\n",
      " 9   9            1167341 non-null  float64\n",
      " 10  10           1167341 non-null  float64\n",
      " 11  11           1167341 non-null  float64\n",
      " 12  12           1167341 non-null  float64\n",
      " 13  13           1167341 non-null  float64\n",
      " 14  14           1167341 non-null  float64\n",
      " 15  15           1167341 non-null  float64\n",
      " 16  16           1167341 non-null  float64\n",
      " 17  17           1167341 non-null  float64\n",
      " 18  18           1167341 non-null  float64\n",
      " 19  19           1167341 non-null  float64\n",
      " 20  20           1167341 non-null  float64\n",
      " 21  21           1167341 non-null  float64\n",
      " 22  22           1167341 non-null  float64\n",
      " 23  23           1167341 non-null  float64\n",
      " 24  24           1167341 non-null  float64\n",
      " 25  25           1167341 non-null  float64\n",
      " 26  26           1167341 non-null  float64\n",
      " 27  27           1167341 non-null  float64\n",
      " 28  28           1167341 non-null  float64\n",
      " 29  29           1167341 non-null  float64\n",
      " 30  30           1167341 non-null  float64\n",
      " 31  31           1167341 non-null  float64\n",
      " 32  32           1167341 non-null  float64\n",
      " 33  33           1167341 non-null  float64\n",
      " 34  34           1167341 non-null  float64\n",
      " 35  35           1167341 non-null  float64\n",
      " 36  36           1167341 non-null  float64\n",
      " 37  37           1167341 non-null  float64\n",
      " 38  38           1167341 non-null  float64\n",
      " 39  39           1167341 non-null  float64\n",
      " 40  40           1167341 non-null  float64\n",
      " 41  41           1167341 non-null  float64\n",
      " 42  42           1167341 non-null  float64\n",
      " 43  43           1167341 non-null  float64\n",
      " 44  44           1167341 non-null  float64\n",
      " 45  45           1167341 non-null  float64\n",
      " 46  46           1167341 non-null  float64\n",
      " 47  47           1167341 non-null  float64\n",
      " 48  48           1167341 non-null  float64\n",
      " 49  49           1167341 non-null  float64\n",
      " 50  50           1167341 non-null  float64\n",
      " 51  51           1167341 non-null  float64\n",
      " 52  52           1167341 non-null  float64\n",
      " 53  label        1167341 non-null  int64  \n",
      " 54  ticker       1167341 non-null  int64  \n",
      " 55  month_1      1167341 non-null  uint8  \n",
      " 56  month_2      1167341 non-null  uint8  \n",
      " 57  month_3      1167341 non-null  uint8  \n",
      " 58  month_4      1167341 non-null  uint8  \n",
      " 59  month_5      1167341 non-null  uint8  \n",
      " 60  month_6      1167341 non-null  uint8  \n",
      " 61  month_7      1167341 non-null  uint8  \n",
      " 62  month_8      1167341 non-null  uint8  \n",
      " 63  month_9      1167341 non-null  uint8  \n",
      " 64  month_10     1167341 non-null  uint8  \n",
      " 65  month_11     1167341 non-null  uint8  \n",
      " 66  month_12     1167341 non-null  uint8  \n",
      "dtypes: float64(53), int64(2), uint8(12)\n",
      "memory usage: 507.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "To respect the time series nature of the data, we set aside the data at the end of the sample as hold-out or test set. More specifically, we'll use the data for 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:56.219667Z",
     "start_time": "2021-02-23T15:28:56.153146Z"
    }
   },
   "outputs": [],
   "source": [
    "window_size=52\n",
    "sequence = list(range(1, window_size+1))\n",
    "ticker = 1\n",
    "months = 12\n",
    "n_tickers = data.ticker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.038843Z",
     "start_time": "2021-02-23T15:28:56.221179Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = data.drop('fwd_returns', axis=1).loc[idx[:, :'2016'], :]\n",
    "test_data = data.drop('fwd_returns', axis=1).loc[idx[:, '2017'],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each train and test dataset, we generate a list with three input arrays containing the return series, the stock ticker (converted to integer values), and the month (as an integer), as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.140100Z",
     "start_time": "2021-02-23T15:28:57.039880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1035424, 52, 1), (1035424,), (1035424, 12)], (1035424,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [\n",
    "    train_data.loc[:, sequence].values.reshape(-1, window_size , 1),\n",
    "    train_data.ticker,\n",
    "    train_data.filter(like='month')\n",
    "]\n",
    "y_train = train_data.label\n",
    "[x.shape for x in X_train], y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.160607Z",
     "start_time": "2021-02-23T15:28:57.143176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(131917, 52, 1), (131917,), (131917, 12)], (131917,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the last year for testing\n",
    "X_test = [\n",
    "    test_data.loc[:, list(range(1, window_size+1))].values.reshape(-1, window_size , 1),\n",
    "    test_data.ticker,\n",
    "    test_data.filter(like='month')\n",
    "]\n",
    "y_test = test_data.label\n",
    "[x.shape for x in X_test], y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define the Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functional API of Keras makes it easy to design architectures with multiple inputs and outputs. This example illustrates a network with three inputs, as follows:\n",
    "\n",
    "- A two stacked LSTM layers with 25 and 10 units respectively\n",
    "- An embedding layer that learns a 10-dimensional real-valued representation of the equities\n",
    "- A one-hot encoded representation of the month\n",
    "\n",
    "This can be constructed using just a few lines - see e.g., \n",
    "- the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/), \n",
    "- the [LSTM documentation](https://keras.io/layers/recurrent/).\n",
    "\n",
    "Make sure you are initializing your optimizer given the [keras-recommended approach for RNNs](https://keras.io/optimizers/) \n",
    "\n",
    "We begin by defining the three inputs with their respective shapes, as described here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.167073Z",
     "start_time": "2021-02-23T15:28:57.162712Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.189183Z",
     "start_time": "2021-02-23T15:28:57.168941Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.208667Z",
     "start_time": "2021-02-23T15:28:57.191030Z"
    }
   },
   "outputs": [],
   "source": [
    "returns = Input(shape=(window_size, n_features),\n",
    "                name='Returns')\n",
    "\n",
    "tickers = Input(shape=(1,),\n",
    "                name='Tickers')\n",
    "\n",
    "months = Input(shape=(12,),\n",
    "               name='Months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define stacked LSTM layers, we set the `return_sequences` keyword to `True`. This ensures that the first layer produces an output that conforms to the expected three-dimensional input format. Note that we also use dropout regularization and how the functional API passes the tensor outputs from one layer to the subsequent layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:57.213641Z",
     "start_time": "2021-02-23T15:28:57.210584Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm1_units = 25\n",
    "lstm2_units = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.418915Z",
     "start_time": "2021-02-23T15:28:57.215252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:43:40.326636: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 16:43:40.327435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:40.327631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:40.327686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:41.830475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:41.830596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:41.830607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-17 16:43:41.830655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 16:43:41.830688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5947 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "lstm1 = LSTM(units=lstm1_units, \n",
    "             input_shape=(window_size, \n",
    "                          n_features), \n",
    "             name='LSTM1', \n",
    "             dropout=.2,\n",
    "             return_sequences=True)(returns)\n",
    "\n",
    "lstm_model = LSTM(units=lstm2_units, \n",
    "             dropout=.2,\n",
    "             name='LSTM2')(lstm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer requires the `input_dim` keyword, which defines how many embeddings the layer will learn, the `output_dim` keyword, which defines the size of the embedding, and the `input_length` keyword to set the number of elements passed to the layer (here only one ticker per sample). \n",
    "\n",
    "To combine the embedding layer with the LSTM layer and the months input, we need to reshape (or flatten) it, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.442744Z",
     "start_time": "2021-02-23T15:28:58.424522Z"
    }
   },
   "outputs": [],
   "source": [
    "ticker_embedding = Embedding(input_dim=n_tickers, \n",
    "                             output_dim=5, \n",
    "                             input_length=1)(tickers)\n",
    "ticker_embedding = Reshape(target_shape=(5,))(ticker_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Model components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can concatenate the three tensors and add fully-connected layers to learn a mapping from these learned time series, ticker, and month indicators to the outcome, a positive or negative return in the following week, as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.516368Z",
     "start_time": "2021-02-23T15:28:58.448375Z"
    }
   },
   "outputs": [],
   "source": [
    "merged = concatenate([lstm_model, \n",
    "                      ticker_embedding, \n",
    "                      months], name='Merged')\n",
    "\n",
    "bn = BatchNormalization()(merged)\n",
    "hidden_dense = Dense(10, name='FC1')(bn)\n",
    "\n",
    "output = Dense(1, name='Output', activation='sigmoid')(hidden_dense)\n",
    "\n",
    "rnn = Model(inputs=[returns, tickers, months], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary lays out this slightly more sophisticated architecture with 29,371 parameters, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.533718Z",
     "start_time": "2021-02-23T15:28:58.522029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Returns (InputLayer)           [(None, 52, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " Tickers (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " LSTM1 (LSTM)                   (None, 52, 25)       2700        ['Returns[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 5)         12445       ['Tickers[0][0]']                \n",
      "                                                                                                  \n",
      " LSTM2 (LSTM)                   (None, 10)           1440        ['LSTM1[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 5)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " Months (InputLayer)            [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " Merged (Concatenate)           (None, 27)           0           ['LSTM2[0][0]',                  \n",
      "                                                                  'reshape[0][0]',                \n",
      "                                                                  'Months[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 27)          108         ['Merged[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " FC1 (Dense)                    (None, 10)           280         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " Output (Dense)                 (None, 1)            11          ['FC1[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,984\n",
      "Trainable params: 16,930\n",
      "Non-trainable params: 54\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model to compute a custom auc metric as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.543044Z",
     "start_time": "2021-02-23T15:28:58.537703Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.RMSprop(lr=0.001,\n",
    "                                        rho=0.9,\n",
    "                                        epsilon=1e-08,\n",
    "                                        decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.673804Z",
     "start_time": "2021-02-23T15:28:58.546460Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy', \n",
    "                     tf.keras.metrics.AUC(name='AUC')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.682620Z",
     "start_time": "2021-02-23T15:28:58.675306Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_path = (results_path / 'lstm.classification.h5').as_posix()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=lstm_path,\n",
    "                               verbose=1,\n",
    "                               monitor='val_AUC',\n",
    "                               mode='max',\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:28:58.689723Z",
     "start_time": "2021-02-23T15:28:58.683968Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_AUC', \n",
    "                              patience=5,\n",
    "                              restore_best_weights=True,\n",
    "                              mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:13.725627Z",
     "start_time": "2021-02-23T15:28:58.691174Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:43:58.093933: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 215368192 exceeds 10% of free system memory.\n",
      "2023-02-17 16:43:58.376202: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 215368192 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:44:02.341776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2299/32357 [=>............................] - ETA: 9:09 - loss: 0.6954 - accuracy: 0.5213 - AUC: 0.5260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[1;32m      2\u001b[0m                    y_train,\n\u001b[1;32m      3\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                    batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                    validation_data\u001b[39m=\u001b[39;49m(X_test, y_test),\n\u001b[1;32m      6\u001b[0m                    callbacks\u001b[39m=\u001b[39;49m[early_stopping, checkpointer],\n\u001b[1;32m      7\u001b[0m                    verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4t/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = rnn.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks=[early_stopping, checkpointer],\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training stops after 18 epochs, producing a test area under the curve (AUC) of 0.63 for the best model with 13 rounds of training (each of which takes around three minutes on a single GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:13.729165Z",
     "start_time": "2021-02-23T16:17:13.726733Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "loss_history = pd.DataFrame(training.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:13.744015Z",
     "start_time": "2021-02-23T16:17:13.730655Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def which_metric(m):\n",
    "    return m.split('_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:14.585829Z",
     "start_time": "2021-02-23T16:17:13.744917Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(18,4))\n",
    "for i, (metric, hist) in enumerate(loss_history.groupby(which_metric, axis=1)):\n",
    "    hist.plot(ax=axes[i], title=metric)\n",
    "    axes[i].legend(['Training', 'Validation'])\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'lstm_stacked_classification', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:20.427831Z",
     "start_time": "2021-02-23T16:17:14.586859Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predict = pd.Series(rnn.predict(X_test).squeeze(), index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:20.456084Z",
     "start_time": "2021-02-23T16:17:20.428744Z"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_score=test_predict, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:20.461598Z",
     "start_time": "2021-02-23T16:17:20.456961Z"
    }
   },
   "outputs": [],
   "source": [
    "((test_predict>.5) == y_test).astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:17:20.484800Z",
     "start_time": "2021-02-23T16:17:20.462606Z"
    }
   },
   "outputs": [],
   "source": [
    "spearmanr(test_predict, y_test)[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "434ef85c3fb5a296e505a484f164c3e4672a7a65819d5b3b14e63d027f7747a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
